---
title: "Using httr to interact with APIs directly"
output: html_document
---

# Using httr to interact with APIs directly

If an API client doesn't exist, it's up to you to communicate directly with the API. But don't worry, the package `httr` makes this really straightforward. In this chapter you'll learn how to make web requests from R, how to examine the responses you get back and some best practices for doing this in a responsible way.

## GET and POST requests in theory

HTTP requests

- Conversation between your machine and the server 
- First: what you want to happen
- "methods" - different requests for different tasks

GET and POST

- GET: 'get me something'
- POST: 'have something of mine'

Other types

- HEAD - just like head()
- DELETE - 'remove this thing'
- Many others! But GET and POST are the big ones

Making GET requests with httr

> response <- GET(url = "https://httpbin.org/get") > content(response)
$args
named list()
$headers
$headers$Accept
[1] "application/json, text/xml, application/xml, */*" ...

Making POST requests with httr
> response <- POST(url = "https://httpbin.org/post")

## GET requests in practice {.tabset .tabset-fade .tabset-pills}

### Exercise

To start with you're going to make a GET request. As discussed in the video, this is a request that asks the server to give you a particular piece of data or content (usually specified in the URL). These make up the majority of the requests you'll make in a data science context, since most of the time you'll be getting data from servers, not giving it to them.

To do this you'll use the `httr` package, written by Hadley Wickham (of course), which makes HTTP requests extremely easy. You're going to make a very simple GET request, and then inspect the output to see what it looks like.

### Instructions

- Load the httr package.
- Use the GET() function to make a request to http://httpbin.org/get, saving the result to `get_result`.
- Print `get_result` to inspect it.

### script.R

```{r, collapse=TRUE}
# Load the httr package
library("httr")

# Make a GET request to http://httpbin.org/get
get_result <- GET("http://httpbin.org/get")

# Print it to inspect it
get_result
```

## POST requests in practice {.tabset .tabset-fade .tabset-pills}

### Exercies

Next we'll look at POST requests, also made through httr, with the function (you've guessed it) POST(). Rather than asking the server to give you something, as in GET requests, a POST request asks the server to accept something from you. They're commonly used for things like file upload, or authentication. As a result of their use for uploading things, `POST()` accepts not just a `url` but also a `body` argument containing whatever you want to give to the server.

You'll make a very simple POST request, just uploading a piece of text, and then inspect the output to see what it looks like.

### Instructions

- Load the httr package.
- Make a POST request with the URL http://httpbin.org/post and the body `"this is a test"`, saving the result to post_result.
- Print post_result to inspect it.

### script.R

```{r, collapse=TRUE}
# Load the httr package
library(httr)

# Make a POST request to http://httpbin.org/post with the body "this is a test"
post_result <- POST(url = "http://httpbin.org/post", body = "this is a test")

# Print it to inspect it
post_result
```

## Extracting the response {.tabset .tabset-fade .tabset-pills}

### Exercies

Making requests is all well and good, but it's also not why you're here. What we really want to do is get the data the server sent back, which can be done with httr's `content()` function. You pass it an object returned from a `GET` (or `POST`, or `DELETE`, or...) call, and it spits out whatever the server actually sent in an R-compatible structure.

We're going to demonstrate that now, using a slightly more complicated URL than before - in fact, using a URL from the Wikimedia `pageviews` system you dealt with through the pageviews package, which is stored as `url`. Without looking too much at the structure for the time being (we'll get to that later) this request asks for the number of pageviews to the English-language Wikipedia's "Hadley Wickham" article on 1 and 2 January 2017.

### Instructions

httr is loaded in your workspace.

- Make a GET request using the `url` object as the URL. Save the results as `pageview_response`.
- Call `content()` on `pageview_response` to retrieve the data the server has sent back. Save the data as `pageview_data`.
- Examine `pageview_data` with `str()`.

### script.R

```{r}
library(httr)

url <- "https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia.org/all-access/all-agents/Hadley_Wickham/daily/20170101/20170102"

# Make a GET request to url and save the results
pageview_response <- GET(url)

# Call content() to retrieve the data the server sent back
pageview_data <- content(pageview_response)

# Examine the results with str()
str(pageview_data)
```

## Multiple Choice: GET and POST requests {.tabset .tabset-fade .tabset-pills}

### Question

We've now discussed multiple types of HTTP request - including GET requests, for retrieving data, and POST requests, for transmitting it - as well as how to extract the server response once a request is complete. What sort of request would you use to send a server data?

### Answer

Possible Answers

[x] GET request      
[o] POST request

## Graceful httr

Error handling

- Every response includes a HTTP status code

    ```
    > response <- GET("https://httpbin.org/get")       
      Response [https://httpbin.org/get]      
      Date: 2017-08-24 20:29     
      Status: 200     
      Content-Type: application/json Size: 330 B      
      { ...    
    ```

Understanding status codes

- Code starts with: 
    - 2 - great!
    - 3 - great!
    - 4 - your code is broken 5 - their code is broken
- https://en.wikipedia.org/wiki/List_of_HTTP_status_codes
- Check for bad codes with http_error()

URL construction

- Most of URL doesn't change
- Stitch URLs together from bits that don't change with the bits that do 
- Saves thinking and typing

Directory-based URLs

- Slash-separated, like directories 
- https://fakeurl.com/api/peaches/thursday
- Use paste(), with sep = "/"

Parameter-based URLs

- Uses URL parameters (a=1&b=2) 
- https://fakeurl.com/api.php?fruit=peaches&day=thursday 
- Use GET() to construct the URL with query argument

## Handling http failures {.tabset .tabset-fade .tabset-pills}

### Exercies

As mentioned, HTTP calls can go wrong. Handling that can be done with httr's http_error() function, which identifies whether a server response contains an error.

If the response does contain an error, calling `http_error()` over the response will produce `TRUE`; otherwise, `FALSE`. You can use this for really fine-grained control over results. For example, you could check whether the request contained an error, and (if so) issue a warning and re-try the request.

For now we'll try something a bit simpler - issuing a warning that something went wrong if `http_error()` returns `TRUE`, and printing the content if it doesn't.

### Instructions

- Make a httr `GET()` request to the URL stored as `fake_url`, and store the result as `request_result`.
- If `http_error()` returns `TRUE`, use `warning()` to issue the warning "The request failed".
- If not, use `content()` (as demonstrated in previous exercises) to print the contents of the result.


### script.R

```{r, collapse=TRUE}
fake_url <- "http://google.com/fakepagethatdoesnotexist"

# Make the GET request
request_result <- GET(fake_url)

# Check request_result
if(http_error(request_result)){
	warning("The request failed")
} else {
	content(request_result)
}
```

## Constructing queries (Part I){.tabset .tabset-fade .tabset-pills}

### Exercies

As briefly discussed in the previous video, the actual API query (which tells the API what you want to do) tends to be in one of the two forms. The first is directory-based, where values are separated by `/` marks within the URL. The second is parameter-based, where all the values exist at the end of the URL and take the form of `key=value`.

Constructing directory-based URLs can be done via paste(), which takes an unlimited number of strings, along with a separator, as sep. So to construct `http://swapi.co/api/vehicles/12` we'd call:

> paste("http://swapi.co", "api", "vehicles", "12", sep = "/")

Let's do that now! We'll cover parameter-based URLs later. In the mean time we can play with SWAPI, mentioned above, which is an API chock full of star wars data. This time, rather than a vehicle, we'll look for a person.

### Instructions

httr is loaded in your workspace.

- Construct a directory-based API URL to `http://swapi.co/api`, looking for person `1` in `people`.
- Assign the URL to `directory_url`.
- Use `GET` to make an API call with `directory_url`.

### script.R

```{r, collapse=TRUE}
# Construct a directory-based API URL to `http://swapi.co/api`,
# looking for person `1` in `people`
directory_url <- paste("http://swapi.co/api", "people", 1, sep = "/")

# Make a GET call with it
result <- GET(directory_url)
```

## Constructing queries (Part II){.tabset .tabset-fade .tabset-pills}

### Exercies

As mentioned (albeit briefly) in the last exercise, there are also parameter based URLs, where all the query values exist at the end of the URL and take the form of `key=value` - they look something like `http://fakeurl.com/foo.php?country=spain&food=goulash`

Constructing parameter-based URLs can also be done with `paste()`, but the easiest way to do it is with `GET()` and `POST()` themselves, which accept a `query` argument consisting of a list of keys and values. So, to continue with the food-based examples, we could construct `fakeurl.com/api.php?fruit=peaches&day=thursday` with:

> GET("fakeurl.com/api.php", query = list(fruit = "peaches", day = "thursday"))

In this exercise you'll construct a call to `https://httpbin.org/get?nationality=americans&country=antigua`

### Instructions

- Start by contructing the `query_params` list, with a `nationality` parameter of `"americans"` and a `country` parameter of `"antigua"`.
- Construct a parameter-based call to `https://httpbin.org/get`, using `GET()` passing `query_params` to the `query` arugment.
- Print the response `parameter_response`.

### script.R

```{r, collapse=TRUE}
# Create list with nationality and country elements
query_params <- list(nationality = "americans", 
    country = "antigua")
    
# Make parameter-based call to httpbin, with query_params
parameter_response <- GET("https://httpbin.org/get", query = query_params)

# Print parameter_response
parameter_response
```

## Respectful API usage

User agents

- Bits of text that ID your browser (or software)
- Gives the server some idea of what you're trying to do 
- You can set one with your requests with user_agent() 
- Add an email address so they can contact you.

Rate limiting

- Too many requests makes for a sad server
- Deliberately slows down your code to keep under a desired 'rate' 
- Slows you, but avoids getting you banned from the server

## Using user agents{.tabset .tabset-fade .tabset-pills}

### Exercies

As discussed in the video, informative user-agents are a good way of being respectful of the developers running the API you're interacting with. They make it easy for them to contact you in the event something goes wrong. I always try to include:

1. My email address;
2. A URL for the project the code is a part of, if it's got a URL.

Building user agents is done by passing a call to `user_agent()` into the `GET()` or `POST()` request; something like:

`GET("http://url.goes.here/", user_agent("somefakeemail@domain.com http://project.website"))`

In the event you don't have a website, a short one-sentence description of what the project is about serves pretty well.

### Instructions

- Make a `GET()` request to `url`.
- Include a user agent that has a fake email address `"my@email.address"` followed by the sentence `"this is a test"`.
- Assign the response to `server_response`.

### script.R

```{r, collapse=TRUE}
# Do not change the url
url <- "https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia/all-access/all-agents/Aaron_Halfaker/daily/2015100100/2015103100"

# Add the email address and the test sentence inside user_agent()
server_response <- GET(url, user_agent("my@email.address this is a test"))
```

## Rate-limiting {.tabset .tabset-fade .tabset-pills}

### Exercies
The next stage of respectful API usage is rate-limiting: making sure you only make a certain number of requests to the server in a given time period. Your limit will vary from server to server, but the implementation is always pretty much the same and involves a call to [`Sys.sleep()`](https://www.rdocumentation.org/packages/base/topics/Sys.sleep). This function takes one argument, a number, which represents the number of seconds to "sleep" (pause) the R session for. So if you call `Sys.sleep(15)`, it'll pause for 15 seconds before allowing further code to run.

As you can imagine, this is really useful for rate-limiting. If you are only allowed 4 requests a minute? No problem! Just pause for 15 seconds between each request and you're guaranteed to never exceed it. Let's demonstrate now by putting together a little loop that sends multiple requests on a 5-second time delay. We'll use `httpbin.org` 's APIs, which allow you to test different HTTP libraries.

### Instructions

- Construct a vector of 2 URLs, `http://httpbin.org/status/404` and `http://httpbin.org/status/301`.
- Write a for-loop that sends a `GET()` request to each one.
- Ensure that the for-loop uses `Sys.sleep()` to delay for 5 seconds between request.

### script.R

```{r, collapse=TRUE}
# Construct a vector of 2 URLs
urls <- c("http://httpbin.org/status/404", "http://httpbin.org/status/301")

for(url in urls){
    # Send a GET request to url
    result <- GET(url)
    # Delay for 5 seconds between requests
    Sys.sleep(5)
}
```

## Tying it all together{.tabset .tabset-fade .tabset-pills}

### Exercies

Tying it all together

Using everything that you learned in the chapter, let's make a simple replica of one of the 'pageviews' functions - building queries, sending GET requests (with an appropriate user agent) and handling the output in a fault-tolerant way. You'll build this function up piece by piece in this exercise.

To output an error, you will use the function stop(), which takes a string as an argument, stops the execution of the program, and outputs the string as an error. You can try it right now by running `stop("This is an error")`.

### Instructions

STEP1:
First, get the function to construct the url.

- In the call to paste(), add article_title as the second argument to construct url.

STEP2:
Now, make the request.

- Use GET() to request url with a user agent "my@email.com this is a test".

STEP3:
Now, add an error check.

- Check the response for errors with http_error(), throwing an error of "the request failed" with stop() if there was one.

STEP4:

- Finally, instead of returning response, return the content() of the response.

### script.R

```{r}
get_pageviews <- function(article_title){
  url <- paste(
    "https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia/all-access/all-agents", 
    # Include article title
    article_title, 
    "daily/2015100100/2015103100", 
    sep = "/"
  )   
  # Get the webpage  
  response <- GET(url, user_agent("my@email.com this is a test")) 
  # Is there an HTTP error?
  if(http_error(response)){ 
    # Throw an R error
    stop("the request failed") 
  }
  # Return the response's content
  content(response)
}
```